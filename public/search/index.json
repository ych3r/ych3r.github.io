[{"categories":["machine learning"],"content":" I completed Andrew Ng\u0026rsquo;s Machine Learning Specialization course. And somehow, I\u0026rsquo;m still confused\u0026hellip;\nCourse 1: I\u0026rsquo;ve learned supervised machine learning, including regression and classification. Course 2: I\u0026rsquo;ve learned some advanced learning algorithms, like neural network and decision trees. Course 3: I\u0026rsquo;ve learned unsupervised machine learning, recommender systems, and reinforcement learning. But hey, I understood each concept (at some level), but my understanding is not holistic. I still have no idea how to use machine learning as a tool.\nSo, let\u0026rsquo;s try to connect all ML concepts.\nFirst of all, what does machine learning do?\nWe humans always want to use formulas to explain the patterns of the world. However, not everyone is Ramanujan, figuring out the right formula is hard. So, computer scientists started to think, if we have enough data, why not let the computer brute force the correct function? Turns out it works.\nMachine learning tries to find the right function by learning the data.\nSome ML models can predict house price, some can detect spam emails, some can recommend movies, etc.\nSo, what model can we use?\nWe have classical ML models, like:\nLinear regression Logistic regression Decision Tree Random Tree XGBoost All these models require some feature engineering, i.e., we need to figure out what features matter. To predict house price, we need to know house type, size, year built, etc.\nIf the problem is too complicated, we can\u0026rsquo;t easily find features, then we let model to find more features. That\u0026rsquo;s Neural Networks, it includes:\nMLP (Basic neural network) And Deep Learning is just neural networks with many layers (deeper).\nCNN RNN Transformer Machine Learning Models ├── Classical ML Models │ └── Neural Network Models ├── Shallow Neural Networks └── Deep Learning Models (Deep Neural Networks) Next, how to train the models?\nThere are roughly three learning types:\nSupervised Learning: we know the right answer, so we clearly know how well the model does. Unsupervised Learning: we don\u0026rsquo;t know the answer, but we hope the model can find some patterns. Reinforcement Learning: we give rewards if the model does well. LEARNING TYPE ┌─────────────┬─────────────┬──────────────────┐ MODEL TYPE │ Supervised │ Unsupervised│ Reinforcement │ ────────────────┼─────────────┼─────────────┼──────────────────┤ Classical ML │ ✔ (most) │ ✔ (some) │ ✖ (rare) │ │ regression │ k-means/PCA │ │ │ trees │ │ │ ────────────────┼─────────────┼─────────────┼──────────────────┤ Neural Network │ ✔ (common) │ ✔ (autoenc) │ ✔ (deep RL) │ │ MLP/CNN/RNN │ autoencoder │ DQN, PPO │ ────────────────┼─────────────┼─────────────┼──────────────────┤ Deep Learning │ ✔ (very common) │ CNN, Transf │ ✔ (GAN,VAE) │ ✔ (DQN,PPO) │ └─────────────┴─────────────┴──────────────────┘ Wait, I\u0026rsquo;m more confused. What model should I choose to train?\nThat depends on the problem, every model solves a particular type of pattern in data.\nPattern complexity: Classical \u0026lt; Neural networks \u0026lt; Deep learning\nSTART | v Identify DATA Type | ┌───────────────────────┼────────────────────────┬────────────────────┐ v v v v TABULAR IMAGES TEXT/NLP TIME SERIES (spreadsheets) (pixels) (language) (sequences) | | | | v v v v Small dataset? Use CNN Use Transformer Use LSTM / | (BERT/GPT/T5) Transformer Yes | No | v v Predict? Use Use NNs/Deep ML (Next value?) Classical ML | (XGBoost) v LSTM/Transformer This chart can help you solve 90% of ML problems.\nNow, let\u0026rsquo;s think about how to solve real world problem or win a Kaggle competition.\nDefine the problem Supervised Unsupervised Reinforcement Pick a baseline model tabular -\u0026gt; XGBoost images -\u0026gt; CNN text -\u0026gt; Transformer Feature engineering Train, fine tuning, evaluate Deploy (for real world project) By writing this blog, I realized that machine learning isn\u0026rsquo;t about memorizing all the model, but about understanding the problem and finding the right tool.\nActually, Machine learning is quite similar to Data Structure and Algorithm. You can use whatever method you want to solve the problem, but there must be a more suitable algorithm for that particular problem.\nThanks for reading!\nall the flowcharts are generated by a famous Transformer AI model ","permalink":"https://liuyuchen.dev/posts/ml-intro/","tags":[""],"title":"Machine Learning Introduction"},{"categories":["money"],"content":" Recently, I finished reading a book called \u0026lsquo;The Millionaire Next Door\u0026rsquo;. Most of the content is talking about common sense, like how to live a frugal life, which most people have already done. It actually brings out an interesting formula about how to categorize your financial status.\nExpected Net Worth = (Age x Annual Income) / 10 If your actual net worth is double than the expected number, then you are a \u0026lsquo;PAW (Prodigious accumulator of wealth)\u0026rsquo;. If your actual net worth is less than half of the expected number, then you are a \u0026lsquo;UAW (Under accumulator of wealth)\u0026rsquo;. If you are something in between, like most people, you are an \u0026lsquo;AAW (Average Accumulator of Wealth)\u0026rsquo;. PAW means you live below your means-you are wealthy compared with your lifestyle. Obviously, you should try to be a \u0026lsquo;PAW\u0026rsquo;.\nIn this book, the author indicates that most millionaires are very low-key-they don\u0026rsquo;t live in mansions and drive fancy cars, they are among us. The difference is that when a financial crisis comes, they still live comfortably.\nI recently moved to a lower-middle-class neighborhood. Before reading this book, I thought I was kind of rich here-I have a decent job in the city, while most of the people here are blue-collar. After living here for a while, I realized I was terribly wrong. Our building janitor, who lives next door, is a landlord of multiple houses, and he has his own business-he took this job just to kill time.\nI understand that living a frugal life is good for wealth growing, but I do want big houses and fancy cars, how do I get them?\nI think the idea of this book is to distinguish between the actual rich and the fake rich. When a UAW purchases the latest iPhone, he/she lose the money for an iPhone. When a PAW purchases the same iPhone, his/her net worth might not be affected. Same idea with houses and cars.\nI built a small tool to help you become a PAW, code is below.\n/* version: java 25.0.1 save this code into: \u0026#39;Paw.java\u0026#39; in terminal, run: javac Paw.java java Paw */ import java.util.*; class Paw { public static void main(String[] args) { Scanner sc = new Scanner(System.in); System.out.printf(\u0026#34;Your age: \u0026#34;); int age = sc.nextInt(); System.out.printf(\u0026#34;Your annual income: $\u0026#34;); float annual_income = sc.nextFloat(); System.out.printf(\u0026#34;Your current net worth: $\u0026#34;); float net_worth = sc.nextFloat(); sc.close(); float expected_net_worth = (age * annual_income) / 10; if (net_worth \u0026gt; (2 * expected_net_worth)) { System.out.println(\u0026#34;Congrats! You are a PAW!\u0026#34;); } else if (net_worth \u0026lt; (expected_net_worth / 2)) { System.out.println(\u0026#34;Sorry, you are currently a UAW\u0026#34;); } else { System.out.println(\u0026#34;You are an AAW\u0026#34;); } } } ","permalink":"https://liuyuchen.dev/posts/paw-uaw/","tags":["personal finance"],"title":"PAW vs UAW"},{"categories":["Coding"],"content":" Before saying someone\u0026rsquo;s code is sh*t code, you should know what is good code.\nApart from those that are not readable, in general, the good code should run fast and take up less memory space. Everyone can say their code is good, but how do you prove it? Simply monitoring runtime and memory space may not be accurate due to various factors-the data matters, and hardware also matters. A more scientific way to do so is to look at the \u0026ldquo;trend\u0026rdquo;-if the number of items grows, how would the time and space grow?\nBig O is used to describe the time complexity or space complexity of algorithms.\nTime Complexity Most of the time when talking about big O, people refer to time complexity. For example, a for loop enumerates n items, then its time complexity is O(n).\nWhy does this matter? Because in real-world applications, this n could be extremely large. A small difference in algorithm design can increase the time by a huge amount. Just think of GTA online loading time (story ).\nSo here\u0026rsquo;s how we do big O analysis:\nThink about the \u0026ldquo;Worst Case\u0026rdquo; Given an array, we want to find an item. The position of that item matters to the computation time, but we only consider the worst-case scenario, where the item is positioned last. Remove Constants A function might have more than one loop and some other commands: O(2n + 3) If the n is a million or more, drop the constants because they don\u0026rsquo;t matter: O(n) Different terms for inputs If there are two input arrays, each of them has a loop. Because we don\u0026rsquo;t know their size, we can\u0026rsquo;t combine them together, so: O(a + b) If there\u0026rsquo;s a nested function, it could be O(n * n) = O(n^2) Drop Non Dominants If the big O for a function is O(n + n^2), we drop n because n^2 is more important: O(n^2) But how does this help me learn data structures and algorithms?\nWe all know that a program combines data structures and algorithms. A data structure stores the data, and an algorithm processes it.\nUsing big O notation, we can determine which data structure and algorithm to choose. For example, accessing an item in an array is O(1), while searching for an item takes O(n).\nSpace Complexity The reason people don\u0026rsquo;t talk about \u0026ldquo;space complexity\u0026rdquo; that much is that hardware is cheap nowadays. But still, terrible algorithm can cause issues like stack overflow.\nSpace complexity is mainly focus on \u0026ldquo;additional space\u0026rdquo;. If the input is a super huge array but the function only print the items out, it would be O(1) because it doesn\u0026rsquo;t add any space. If we copy that into a new array, then the space complexity would be O(n).\nConclusion So, what is good code?\nIt should be \u0026ldquo;readable\u0026rdquo; and clean, so other people can maintain it. It should have fast \u0026ldquo;speed\u0026rdquo;, so it can scale. It should not use a lot of \u0026ldquo;memory\u0026rdquo;, so it doesn\u0026rsquo;t take too much resources. Big-O Cheat Sheet: link O(1) Constant no loops O(log N) Logarithmic searching algorithms O(n) Linear normal for loop O(n*log(n)) Log Linear sorting algorithms O(n^2) Quadratic e.g. two nested loops O(2^n) Exponential recursive algorithms O(n!) Factorial don\u0026rsquo;t do it ","permalink":"https://liuyuchen.dev/posts/big-o/","tags":["big O"],"title":"What is Good Code"},{"categories":["machine learning"],"content":" The other day, our tech lead suggested we implement supervised machine learning to automate our ticket approval system.\nHe said it would be very easy.\nI had no idea how it worked-and honestly, I was confused. Why not just use if-else statements?\nProblem Statement We have a ticket approval system, a platform for reviewing tickets that request access to some resource. With an increasing number of tickets being submitted, manually reviewing them has become inefficient.\nSo, we are seeking a machine learning solution to automate this process.\nWhat is Machine Learning Machine learning is about extracting knowledge from data. Given tons of data, a machine learning model might discover the pattern and thus help people make predictions.\nThere are two most common types:\nSupervised learning algorithms learn from known input/output. Because we already know the answer, that\u0026rsquo;s why it\u0026rsquo;s called \u0026ldquo;supervised\u0026rdquo;. Common applications are like \u0026ldquo;Email spam detection\u0026rdquo; and \u0026ldquo;House price prediction\u0026rdquo;. Unsupervised learning algorithms only has known input. It\u0026rsquo;s more about grouping and finding the pattern. Common applications are like \u0026ldquo;Customer segmentation\u0026rdquo; and \u0026ldquo;Noise reduction\u0026rdquo;. Apparently, we\u0026rsquo;re going to use supervised learning because we have both input (ticket compliance tags) and output (approved or not).\nWhat Does Supervised Machine Learning Do Supervised machine learning is used whenever we want to predict a certain output from a given input. The goal for our project is to make accurate predictions for incoming tickets-should we approve it or not.\nTwo major types of supervised machine learning problems:\nClassification: predict a class label, e.g. classifying irises into one of three possible species. Regression: predict a continuous number, e.g. predicting a person\u0026rsquo;s income from their education, ages, etc. In our case, we just want to classify the new tickets into one of the few choices (approve, deny, escalate).\nWhy Not Just If-Else Why can\u0026rsquo;t we just write a big if-else tree?\nWe human can mess up the complex logic. The problem can be really complicated: edge cases, exceptions, and duplication. Hardcoding the logic might not be a smart choice.\nInstead of trying to figure out every feature, we can let machine learning model (like a decision tree) learns the logic based on data.\nWhat is Decision Tree Decision Trees learn a hierarchy of if/else questions and lead to a decision. We will build a model to distinguish the features instead of building it by hand.\nOther algorithms include:\nK-Nearest Neighbors Lineal Models Naive Bayes Support Vector Machines Neural Networks Among all those fancy algorithms, we chose \u0026lsquo;Decision Trees\u0026rsquo;. I don\u0026rsquo;t know why but let\u0026rsquo;s just assume this is the best algorithm in our case.\nA Simple Example: Breast Cancer Classification Let’s see a real-world example using the breast cancer dataset:\nfrom sklearn.datasets import load_breast_cancer from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split cancer = load_breast_cancer() X_train, X_test, y_train, y_test = train_test_split( cancer.data, cancer.target, stratify=cancer.target, random_state=42) tree = DecisionTreeClassifier(max_depth=4, random_state=0) tree.fit(X_train, y_train) print(\u0026#34;Accuracy on training set: {:.3f}\u0026#34;.format(tree.score(X_train, y_train))) print(\u0026#34;Accuracy on test set: {:.3f}\u0026#34;.format(tree.score(X_test, y_test))) Output:\nAccuracy on training set: 0.988 Accuracy on test set: 0.951 After tuning the max_depth, we got a pretty accurate model.\nPredicting Ticket Approvals Let’s apply a similar approach to a (simplified) version of our ticket system.\nfrom sklearn.tree import DecisionTreeClassifier import pandas as pd # Sample data data = { \u0026#39;Sensitivity\u0026#39;: [\u0026#39;L4\u0026#39;, \u0026#39;L4\u0026#39;, \u0026#39;L3\u0026#39;, \u0026#39;L2\u0026#39;], \u0026#39;Department\u0026#39;: [\u0026#39;HR\u0026#39;, \u0026#39;Dev\u0026#39;, \u0026#39;Dev\u0026#39;, \u0026#39;HR\u0026#39;], \u0026#39;isCompliance\u0026#39;: [True, False, False, False], \u0026#39;inException\u0026#39;: [False, True, False, False], \u0026#39;Approval\u0026#39;: [\u0026#39;No\u0026#39;, \u0026#39;Yes\u0026#39;, \u0026#39;No\u0026#39;, \u0026#39;Yes\u0026#39;] } # Convert to DataFrame df = pd.DataFrame(data) # Encode categorical variables df_encoded = pd.get_dummies(df.drop(\u0026#39;Approval\u0026#39;, axis=1)) y = df[\u0026#39;Approval\u0026#39;] # Train decision tree clf = DecisionTreeClassifier() clf.fit(df_encoded, y) # Predict on new examples test = pd.get_dummies(pd.DataFrame([ { \u0026#39;Sensitivity\u0026#39;: \u0026#39;L4\u0026#39;, \u0026#39;Department\u0026#39;: \u0026#39;Dev\u0026#39;, \u0026#39;isCompliance\u0026#39;: True, \u0026#39;inException\u0026#39;: False }, { \u0026#39;Sensitivity\u0026#39;: \u0026#39;L4\u0026#39;, \u0026#39;Department\u0026#39;: \u0026#39;Security\u0026#39;, \u0026#39;isCompliance\u0026#39;: False, \u0026#39;inException\u0026#39;: True } ])) test = test.reindex(columns=df_encoded.columns, fill_value=0) print(clf.predict(test)) # Output: [\u0026#39;No\u0026#39; \u0026#39;Yes\u0026#39;] Visualizing the Tree.\n# Display the tree from sklearn.tree import export_graphviz export_graphviz(clf, out_file=\u0026#34;ticket.dot\u0026#34;, class_names=[\u0026#34;Yes\u0026#34;, \u0026#34;No\u0026#34;], impurity=False, filled=True) import graphviz from IPython.display import display with open(\u0026#34;ticket.dot\u0026#34;) as f: dot_graph = f.read() graph = graphviz.Source(dot_graph) display(graph) Final Thoughts I wasn’t a fan of AI back in school. I still remember my professor saying:\n“AI is full of unsolved problems.”\nI zoned out and got a B.\nEven when ChatGPT came out, I mostly used it to help study cybersecurity. But once I started working in tech, AI became the elephant in the room. I couldn’t ignore it anymore.\nNow I’m glad I didn’t. I’m still new to it, but I finally understand why machine learning is powerful—and I can’t wait to keep learning and applying it to real-world problems.\nReferences Andreas C. Müller \u0026amp; Sarah Guido: (2016). Introduction to Machine Learning with Python: A Guide for Data Scientists. O\u0026rsquo;Reilly Media, Inc. Our AI friend: ChatGPT ","permalink":"https://liuyuchen.dev/posts/decision-tree/","tags":["decision tree"],"title":"Why Decision Tree \u003e if-else"},{"categories":["web security"],"content":" Recently, when I debugged a web app, I had to add my own test domain to a CORS allowed list there. Then I remembered having seen a CORS vulnerability report before and decided to delve deeper into this topic.\nCreate a Simple Web App with CORS Misconfiguration Essentially, we require a web application with a straightforward login feature and a data endpoint. With misconfigured CORS, we should be able to see the sensitive data from another origin.\nCheck out the code repo: https://github.com/ych3r/vuln-apps/tree/main/cors Because we have a session check, you can\u0026rsquo;t access the sensitive data without login.\ncookie, err := r.Cookie(\u0026#34;session\u0026#34;) if err != nil || cookie.Value != \u0026#34;valid-session\u0026#34; { http.Error(w, \u0026#34;Unauthorized\u0026#34;, http.StatusUnauthorized) return } But once you login, you will get a session cookie (stored in your browser). Try again and you can see the sensitive data. Now we misconfigure the CORS.\norigin := r.Header.Get(\u0026#34;Origin\u0026#34;) if origin != \u0026#34;\u0026#34; { w.Header().Set(\u0026#34;Access-Control-Allow-Origin\u0026#34;, origin) w.Header().Set(\u0026#34;Access-Control-Allow-Credentials\u0026#34;, \u0026#34;true\u0026#34;) } This will allow all the origin to access it.\nAttack it First, we make sure this vulnerability exists. Of course, we test with our own session, and bear with me, I\u0026rsquo;m too lazy to create another profile. Let\u0026rsquo;s just imagine this sensitive data is not the victim\u0026rsquo;s data.\n╰─$ curl -i http://localhost:8080/api/data -H \u0026#34;Origin: xx.com\u0026#34; -H \u0026#34;Cookie: session=valid-session\u0026#34; HTTP/1.1 200 OK Access-Control-Allow-Credentials: true Access-Control-Allow-Origin: xx.com Content-Type: application/json Date: Sat, 07 Jun 2025 17:29:12 GMT Content-Length: 33 {\u0026#34;msg\u0026#34;:\u0026#34;you should not see this\u0026#34;} Great, this website accepts any domain we put in. Then, we create a evil.html that fetch data with the session cookie in the browser using include.\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script\u0026gt; // when fetching a url, the browser automatically sets the Origin header. fetch(\u0026#34;http://localhost:8080/api/data\u0026#34;, { credentials: \u0026#34;include\u0026#34; }).then(res =\u0026gt; res.text()) .then(data =\u0026gt; { alert(\u0026#34;data:\\n\u0026#34; + data) }); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Start a server: python -m http.server and open it in the same browser. We see the secret data.\nWhat does it mean?\nAs long as we let the victim open evil.html, and they happened to have a live session on the service, we will be able to bypass the access control and read sensitive data using their session cookie.\nWe\u0026rsquo;re not going to let it pop up obviously, but we can let it secretly send the data to our server.\nTheory Part What is SOP and why do we use it? Same-origin policy doesn\u0026rsquo;t allow website to interact with other domains. This is used to prevent malicious cross-domain interactions, like stealing private data. SOP is implemented in the browser\u0026rsquo;s internal engine. What is CORS and why do we use it? Cross-origin resource sharing is the relaxation of the SOP. Because many websites do need cross-origin access to subdomains or third-party sites. What are the attack vectors? Wildcard in ACAO: like the example above, it allows any origin to access data. Errors parsing Origin headers: some domain on whitelist are using regular expressions, attackers can add prefix or suffix to it, e.g., normal.com -\u0026gt; notnormal.com or normal.com -\u0026gt; normal.com.evil.net null origin value: the header could be \u0026ldquo;null\u0026rdquo;. Use sandboxed iframe to test it. XSS via trust relationships: if the trusted origin is vulnerable to XSS, attacker could still get sensitive data through it. Breaking TLS: if \u0026lsquo;http\u0026rsquo; is in the whitelist, attacker could use MitM to control that http site, and then exploit the CORS. Intranet access: if there\u0026rsquo;s no Access-Control-Allow-Credentials: true, then attacker can only see unauthenticated content (what\u0026rsquo;s the point then). But the victim\u0026rsquo;s browser can be used as a proxy to access internal sites. Make it Safe Because it’s a configuration problem, the solution is fairly easy. We set up an allowed origin list, then other domains won\u0026rsquo;t be able to fetch data.\norigin := r.Header.Get(\u0026#34;Origin\u0026#34;) allowedOrigins := map[string]bool{ \u0026#34;https://liuyuchen.dev\u0026#34;: true, } if allowedOrigins[origin] { w.Header().Set(\u0026#34;Access-Control-Allow-Origin\u0026#34;, origin) w.Header().Set(\u0026#34;Access-Control-Allow-Credentials\u0026#34;, \u0026#34;true\u0026#34;) } ref:\nCross-origin resource sharing (CORS) - https://portswigger.net/web-security/cors ","permalink":"https://liuyuchen.dev/posts/cors/","tags":["cors"],"title":"Are you from the Same Origin"},{"categories":["misc"],"content":" As a young professional in cybersecurity, do you often feel so dumb that you can\u0026rsquo;t understand some concepts? Maybe my experience can help.\nMy Background I studied Information Security in college. We had the usual foundational CS and math courses, along with cryptography. Back then, the security field seemed straightforward—either you were an attacker or a defender—even though I had no idea how either actually worked.\nLater, I interned at two companies, where I learned about web pentesting and Active Directory security. I thought I was cool because I could \u0026ldquo;hack a machine.\u0026rdquo; But I fell into the certification trap and stayed there for years. I believed that once I got my OSCP, I\u0026rsquo;d land a great job and be set for life. The truth? I never passed the exam and I still got a decent job.\nSince I did well in undergrad, I came to the U.S. for grad school. That’s where I met some truly smart people and started to realize how far behind I was in core computer science. Professors assumed cybersecurity students were already programming experts, but I wasn’t. I struggled. I knew all about vulnerabilities, attack methodologies, and bug bounty business, but I had no idea how the technology worked under the hood. I never read the source code.\nEventually, I landed an internship and then a full-time role as a cloud security operations engineer. I didn’t need to pass LeetCode-style interviews, unlike my SWE friends. But because no one expected me to code, I quickly got bored with the repetitive work. Worse, I noticed that developers looked down on security. They were the ones fixing bugs and our findings were often seen as annoying or low-priority.\nPros and Cons With all these doubts, I began to ask: what if I became a developer? Would that be smarter?\nAs a Cybersecurity Professional\nPros:\nLearn about cool attack techniques. Feel like a hacker. Easier path to senior roles (since I already had experience). Cons:\nSpend a lot of time arguing about insecure configs. Most tools are just scripts, not real software. Lower salary compared to SWE. As a Software Engineer\nPros:\nBuild useful, impactful tools. Fewer pointless meetings. Gain deeper understanding of how products really work. Cons:\nHonestly, it’s harder than security, as you\u0026rsquo;ve got tons to learn. Eventually, I switched to a dev role within the same department and it completely changed how I saw both fields.\nEngineer vs. Analyst YouTube and LinkedIn made it seem like cybersecurity and software development are totally separate careers. That confused me for a long time. But now I see: security is part of the software development lifecycle. The real distinction is not \u0026ldquo;security vs development,\u0026rdquo; but rather analyst vs engineer.\nThe analyst finds the problem. The engineer solves the problem. Both roles matter, but I prefer writing code.\nSince switching, I\u0026rsquo;ve learned so much about how software actually works. I even started reading the source code of new CVEs. And you know what? HackTheBox got easier—and more fun—because of my web dev skills.\nSummary Always aim high because there are no shortcuts. I skipped LeetCode and missed the SWE opportunity early on. I avoided development skills, and that became the bottleneck in my security career.\nIf you\u0026rsquo;re like me, if you want to be a great hacker, become a developer first. You simply can’t skip that step.\n","permalink":"https://liuyuchen.dev/posts/career-change/","tags":[""],"title":"Career Change: From Cybersecurity to Software Development"},{"categories":["web security"],"content":"So, I almost submit my first valid bug report\u0026hellip;\nWhat Happened The other night, I finally decided to give bug bounty a try. I found a VDP program and let ChatGPT write me a recon script. That recon script returned with several subdomains, and when I went through them, a weird domain caught my eye. What the hell is \u0026lsquo;whoami.xx.xx.com\u0026rsquo;?\nOut of curiosity, I opened that in my browser. Holy cow, it looks like a debugging page with an internal IP! I wasn\u0026rsquo;t sure if that counts but ChatGPT said it was a valid information disclosure bug. Before embarrassing myself, I wanted to figure out what this \u0026lsquo;whoami\u0026rsquo; subdomain does.\nIt turns out the whoami subdomain is typically mapped to a developer debug service. It echoes back how the server sees the request \u0026ndash; including headers, IP addresses, and internal network info. From my experience, I know that internal IP can chain with other vulnerabilities which means at least it\u0026rsquo;s a \u0026rsquo;low severity\u0026rsquo;.\nSo, I submitted the report and got a \u0026lsquo;duplicate\u0026rsquo; a few hours later. But that makes sense! I only ran a basic script \u0026ndash; and chances are, many others had already found the same thing before me. The good thing is, that means I found a valid bug!\nWhat Is an Information Disclosure Bug As the name suggests, any sensitive data leak can be information disclosure bug. But this information must be sensitive enough that the company don\u0026rsquo;t want it to be public.\nWhere to Find Info Leaks Can be anywhere as long as it\u0026rsquo;s in scope.\nExposed Subdomains: dev, staging, test, debug, internal Public Files / Directories: credential files JavaScript Files: API keys, usernames, maybe passwords Response Headers: vulnerable software version Error Pages: File path, SQL error, debug messages Publicly Accessible API Responses: sensitive information My Recon Workflow This type of bug heavily rely on recon and you must be faster than anyone else. Thus, writing a script is the only option.\nSubdomains: find as much as possible and monitor their changes. subfinder -d target.com -silent -o subs.txt httpx -l subs.txt -silent -status-code -title -web-server -tech-detect -o live.txt Headers: look for info leak httpx -l live.txt -status-code -web-server -tech-detect -title -o headers.txt Interesting Files \u0026amp; Directories ffuf -u https://FUZZ.target.com -w /usr/share/seclists/Discovery/Web-Content/common.txt -mc 200,403 -t 20 -o ffuf.json JS Files gau target.com | grep \u0026#39;\\.js$\u0026#39; | sort -u \u0026gt; jsfiles.txt python3 LinkFinder/linkfinder.py -i https://target.com/app.js -o cli cat jsfiles.txt | xargs curl -s | grep -Ei \u0026#34;secret|token|api|auth\u0026#34; Error Page: look for debug info, stack traces, SQL errors, Path disclosure Final Thoughts Last but not least, an information disclosure bug is important but it\u0026rsquo;s not like other security bugs. You don\u0026rsquo;t even need a technical background to understand it, maybe you accidentally see leaked information when casually browsing their website.\nHopefully, my blog inspires you to some extent. If you\u0026rsquo;re new to bug bounty like me, don\u0026rsquo;t waste your time on tutorial \u0026ndash; do recon on real target and learn by doing. Even duplicates mean you\u0026rsquo;re doing it right. Anyway, I have to go refine my recon tool, see you ;)\n","permalink":"https://liuyuchen.dev/posts/duplicate-report/","tags":["information disclosure"],"title":"First Duplicate Report"},{"categories":null,"content":" Hi I\u0026rsquo;m Yuchen. I\u0026rsquo;m a Software Engineer :) ","permalink":"https://liuyuchen.dev/about/","tags":null,"title":"Whoami"},{"categories":null,"content":"","permalink":"https://liuyuchen.dev/manifest.json","tags":null,"title":""},{"categories":null,"content":"","permalink":"https://liuyuchen.dev/search/_index.de/","tags":null,"title":""},{"categories":null,"content":"","permalink":"https://liuyuchen.dev/search/_index.es/","tags":null,"title":""},{"categories":null,"content":"","permalink":"https://liuyuchen.dev/search/_index.fr/","tags":null,"title":""},{"categories":null,"content":"","permalink":"https://liuyuchen.dev/search/_index.hi/","tags":null,"title":""},{"categories":null,"content":"","permalink":"https://liuyuchen.dev/search/_index.jp/","tags":null,"title":""},{"categories":null,"content":"","permalink":"https://liuyuchen.dev/search/_index.nl/","tags":null,"title":""},{"categories":null,"content":"","permalink":"https://liuyuchen.dev/search/_index.pl/","tags":null,"title":""},{"categories":null,"content":"","permalink":"https://liuyuchen.dev/search/_index.ru/","tags":null,"title":""},{"categories":null,"content":"","permalink":"https://liuyuchen.dev/search/_index.zh-cn/","tags":null,"title":""}]